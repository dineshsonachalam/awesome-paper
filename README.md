Awesome Resource
----------------
A personal curated list of resources for natrual language processing.


# Papers

## Representation

* Kiros R, Zhu Y, Salakhutdinov RR, Zemel R, Urtasun R, Torralba A, Fidler S. **Skip-thought vectors.** InAdvances in neural information processing systems 2015 (pp. 3294-3302).[PDF](http://papers.nips.cc/paper/5950-skip-thought-vectors.pdf)
* Pennington J, Socher R, Manning CD. **Glove: Global Vectors for Word Representation.** InEMNLP 2014 Oct 25 (Vol. 14, pp. 1532-43). [PDF](http://www-nlp.stanford.edu/pubs/glove.pdf)
* Le QV, Mikolov T. **Distributed Representations of Sentences and Documents.** InICML 2014 Jun 21 (Vol. 14, pp. 1188-1196). [PDF](http://cs.stanford.edu/~quocle/paragraph_vector.pdf)
* Rong X. **word2vec parameter learning explained.** arXiv preprint arXiv:1411.2738. 2014 Nov 11. [PDF](http://www-personal.umich.edu/~ronxin/pdf/w2vexp.pdf)
* Trask A, Michalak P, Liu J. **sense2vec-A fast and accurate method for word sense disambiguation in neural word embeddings.** arXiv preprint arXiv:1511.06388. 2015 Nov 19. [PDF](https://arxiv.org/pdf/1511.06388v1.pdf)
* Nalisnick E, Ravi S. **Infinite dimensional word embeddings.** arXiv preprint arXiv:1511.05392. 2015 Nov 17. [PDF](https://arxiv.org/pdf/1511.05392v2.pdf)
* Bartunov S, Kondrashkin D, Osokin A, Vetrov D. **Breaking Sticks and Ambiguities with Adaptive Skip-gram.** arXiv preprint arXiv:1502.07257. 2015 Feb 25.[PDF](https://arxiv.org/pdf/1502.07257v2.pdf)

## Language Model

* Kim Y, Jernite Y, Sontag D, Rush AM. **Character-aware neural language models.** arXiv preprint arXiv:1508.06615. 2015 Aug 26. ([[PDF](https://arxiv.org/abs/1508.06615)] | [[CODE](https://github.com/yoonkim/lstm-char-cnn)])
* Sutskever I, Martens J, Hinton GE. **Generating text with recurrent neural networks.** InProceedings of the 28th International Conference on Machine Learning (ICML-11) 2011 (pp. 1017-1024).([[PDF](http://www.cs.utoronto.ca/~ilya/pubs/2011/LANG-RNN.pdf)])
* Li J, Ouazzane K, Kazemian HB, Afzal MS. **Neural network approaches for noisy language modeling.** IEEE transactions on neural networks and learning systems. 2013 Nov;24(11):1773-84.
* Chien JT, Ku YC. **Bayesian Recurrent Neural Network for Language Modeling.** IEEE transactions on neural networks and learning systems. 2016 Feb;27(2):361-74.
* Tomas M, Geoffrey Z. **Context Dependent Recurrent Neural Network Language Model.** Microsoft Research Technical Report MSR-TR-2012-92. 2012 Jul. [PDF](https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf)
* Sundermeyer M, Schlüter R, Ney H. **LSTM Neural Networks for Language Modeling.** InInterspeech 2012 Sep (pp. 194-197). [PDF](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.248.4448&rep=rep1&type=pdf)
* Bengio Y, Ducharme R, Vincent P, Jauvin C. **A neural probabilistic language model.** journal of machine learning research. 2003;3(Feb):1137-55.[PDF](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)

## Sentiment Analysis
* Socher R, Perelygin A, Wu JY, Chuang J, Manning CD, Ng AY, Potts C. **Recursive deep models for semantic compositionality over a sentiment treebank.** InProceedings of the conference on empirical methods in natural language processing (EMNLP) 2013 Oct 18 (Vol. 1631, p. 1642). ([[PDF](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.383.1327&rep=rep1&type=pdf)])
* dos Santos CN, Gatti M. **Deep Convolutional Neural Networks for Sentiment Analysis of Short Texts.** InCOLING 2014 (pp. 69-78). [PDF](https://pdfs.semanticscholar.org/b0ac/a3e7877c3c20958b0fae5cbf2dd602104859.pdf)
* Severyn A, Moschitti A. **Twitter sentiment analysis with deep convolutional neural networks.** InProceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval 2015 Aug 9 (pp. 959-962). ACM.[PDF](https://pdfs.semanticscholar.org/9320/a229b450bee8384f218681634e039acd9c2f.pdf)
* Poria S, Cambria E, Gelbukh A. **Deep convolutional neural network textual features and multiple kernel learning for utterance-level multimodal sentiment analysis.** InProceedings of EMNLP 2015 (pp. 2539-2544). [PDF](http://www.aclweb.org/anthology/D/D15/D15-1303.pdf)
* Li C, Xu B, Wu G, He S, Tian G, Hao H. **Recursive Deep Learning for Sentiment Analysis over Social Data.** InProceedings of the 2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)-Volume 02 2014 Aug 11 (pp. 180-185). IEEE Computer Society.
* Balahur A, Steinberger R, Kabadjov M, Zavarella V, Van Der Goot E, Halkia M, Pouliquen B, Belyaeva J. **Sentiment analysis in the news.** arXiv preprint arXiv:1309.6202. 2013 Sep 24. [PDF](https://arxiv.org/pdf/1309.6202v1.pdf)
* Gonçalves P, Araújo M, Benevenuto F, Cha M. **Comparing and combining sentiment analysis methods.** InProceedings of the first ACM conference on Online social networks 2013 Oct 7 (pp. 27-38). ACM.z [PDF](https://arxiv.org/pdf/1406.0032.pdf)
* Liu B, Zhang L. **A survey of opinion mining and sentiment analysis.** InMining text data 2012 (pp. 415-463). Springer US. [PDF](https://pdfs.semanticscholar.org/adff/fadbac235d89bed96aeecb6911c9b2cf6267.pdf)
* Zhou S, Chen Q, Wang X. **Active deep learning method for semi-supervised sentiment classification.** Neurocomputing. 2013 Nov 23;120:536-46.
* Tang D, Qin B, Liu T. **Document modeling with gated recurrent neural network for sentiment classification.** InProceedings of the 2015 Conference on Empirical Methods in Natural Language Processing 2015 (pp. 1422-1432).[PDF](http://ir.hit.edu.cn/~dytang/paper/emnlp2015/emnlp2015.pdf)
* Tang D, Wei F, Qin B, Liu T, Zhou M. **Coooolll: A deep learning system for Twitter sentiment classification.** InProceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014) 2014 Aug 23 (pp. 208-212).[PDF](http://www.aclweb.org/anthology/S14-2#page=228)
* Zharmagambetov AS, Pak AA. **Sentiment analysis of a document using deep learning approach and decision trees.** In2015 Twelve International Conference on Electronics Computer and Computation (ICECCO) 2015 Sep 27 (pp. 1-4). IEEE.
* Zhang X, LeCun Y. **Text understanding from scratch.** arXiv preprint arXiv:1502.01710. 2015 Feb 5. [PDF](https://arxiv.org/pdf/1502.01710.pdf)
* Wang X, Liu Y, Sun C, Wang B, Wang X. **Predicting polarities of tweets by composing word embeddings with long short-term memory.** InProceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing 2015 (Vol. 1, pp. 1343-1353).[PDF](http://www.aclweb.org/anthology/P15-1130)
* Zhang X, Zhao J, LeCun Y. **Character-level convolutional networks for text classification.** InAdvances in Neural Information Processing Systems 2015 (pp. 649-657).[PDF](http://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf)
* Joulin A, Grave E, Bojanowski P, Mikolov T. **Bag of Tricks for Efficient Text Classification.** arXiv preprint arXiv:1607.01759. 2016 Jul 6. [PDF](https://arxiv.org/pdf/1607.01759v3.pdf)
* Kalchbrenner N, Grefenstette E, Blunsom P. **A convolutional neural network for modelling sentences.** arXiv preprint arXiv:1404.2188. 2014 Apr 8.[PDF](https://arxiv.org/pdf/1404.2188.pdf?utm_medium=App.net&utm_source=PourOver)
* A brief review on sentiment analysis. [LINK](http://ieeexplore.ieee.org/document/7755213/)



# Dataset 

## Sentiment
* Stanford Deep Moving [LINK](http://nlp.stanford.edu/sentiment/)
* SAR14 [LINK](https://sites.google.com/site/nquocdai/resources)
* Twitter Sentiment Corpus [LINK](http://www.sananalytics.com/lab/twitter-sentiment/). It consists of 5513 hand-classified tweets. Each tweet was classified with respect to one of four different topics.
* UMICH SI650 - Sentiment Classification [LINK]. Training data: 7086 lines. Test data: 33052 lines, each contains one sentence.
* Sentiment Labelled Sentences Data Set [LINK](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences) 3000 items. This dataset was created for the Paper 'From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015.
* Twitter Data set for Arabic Sentiment Analysis Data Set [LINK](https://archive.ics.uci.edu/ml/datasets/Twitter+Data+set+for+Arabic+Sentiment+Analysis). - By using a tweet crawler, we collect 2000 labelled tweets (1000 positive tweets and 1000 negative ones) on various topics such as: politics and arts. These tweets include opinions written in both 
